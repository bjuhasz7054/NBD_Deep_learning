{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bjuhasz7054/NBD_Deep_learning/blob/main/AutoEncoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-8VCxl_7Omi",
        "outputId": "b74383b3-b226-4f42-9adf-722ad420035c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExauWCrbO3qY"
      },
      "source": [
        "Hyperparameters Config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QH2chdQayQ96"
      },
      "outputs": [],
      "source": [
        "RANDOM_SEED = 42\n",
        "TRAIN_TEST_SPLIT_RATIO = 0.8\n",
        "EPOCHS = 30\n",
        "TRAIN_BATCH_SIZE = 256\n",
        "VALIDATE_BATCH_SIZE = 256\n",
        "DECREASE_RATIO = 1\n",
        "PATIENCE=5\n",
        "LEARNING_RATE=0.001"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnlYK2wr6EsG"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2U-cYQUOx30"
      },
      "source": [
        "Download dataset and labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "le9m_fWQwD8D"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# download dataset\n",
        "!gdown --id 1Z1RqRo0_JiavaZw2yzZG6WETdZQ8qX86\n",
        "!unzip fairface-img-margin025-trainval.zip\n",
        "!rm fairface-img-margin025-trainval.zip\n",
        "\n",
        "# download labels\n",
        "!gdown --id 1i1L3Yqwaio7YSOCj7ftgk8ZZchPG7dmH\n",
        "!gdown --id 1wOdja-ezstMEp81tX1a-EYkFebev4h7D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUWTRUHzPXSV"
      },
      "source": [
        "Initialize dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PegTea4XwwDb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "\n",
        "def split_dataset(base_dataframe, fraction):\n",
        "  first = base_dataframe.sample(frac=fraction, random_state=RANDOM_SEED)\n",
        "  second = base_dataframe.drop(first.index)\n",
        "  return (first, second)\n",
        "\n",
        "initial_train_dataset, _ =  split_dataset(\n",
        "  base_dataframe=pd.read_csv(\n",
        "    \"fairface_label_train.csv\"\n",
        "  ),\n",
        "  fraction=DECREASE_RATIO\n",
        ")\n",
        "\n",
        "validate_labels_df, _ = split_dataset(\n",
        "  base_dataframe=pd.read_csv(\n",
        "    \"fairface_label_val.csv\"\n",
        "  ),\n",
        "  fraction=DECREASE_RATIO\n",
        ")\n",
        "\n",
        "train_labels_df, test_labels_df = split_dataset(\n",
        "  base_dataframe=initial_train_dataset,\n",
        "  fraction=TRAIN_TEST_SPLIT_RATIO\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUXY72M80n7J",
        "outputId": "8e41b2e9-fa3d-46af-9a3c-53c3b0a382df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train percantage = 71.03011320600217%\n",
            "test percantage = 17.757784192102193%\n",
            "validate percantage = 11.212102601895637%\n"
          ]
        }
      ],
      "source": [
        "TRAIN_SIZE = len(train_labels_df)\n",
        "VALIDATE_SIZE = len(validate_labels_df)\n",
        "TEST_SIZE = len(test_labels_df)\n",
        "\n",
        "dataset_size = TRAIN_SIZE + VALIDATE_SIZE + TEST_SIZE\n",
        "print(f\"train percantage = {TRAIN_SIZE / dataset_size * 100}%\")\n",
        "print(f\"test percantage = {TEST_SIZE / dataset_size * 100}%\")\n",
        "print(f\"validate percantage = {VALIDATE_SIZE / dataset_size * 100}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "QGnlj1OcxgYL",
        "outputId": "65166047-3823-4ca2-92b7-b14303cd34e6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>race</th>\n",
              "      <th>service_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>82770</th>\n",
              "      <td>train/82771.jpg</td>\n",
              "      <td>10-19</td>\n",
              "      <td>Male</td>\n",
              "      <td>White</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80112</th>\n",
              "      <td>train/80113.jpg</td>\n",
              "      <td>40-49</td>\n",
              "      <td>Male</td>\n",
              "      <td>Latino_Hispanic</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23469</th>\n",
              "      <td>train/23470.jpg</td>\n",
              "      <td>40-49</td>\n",
              "      <td>Female</td>\n",
              "      <td>Latino_Hispanic</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37598</th>\n",
              "      <td>train/37599.jpg</td>\n",
              "      <td>40-49</td>\n",
              "      <td>Female</td>\n",
              "      <td>East Asian</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63855</th>\n",
              "      <td>train/63856.jpg</td>\n",
              "      <td>40-49</td>\n",
              "      <td>Male</td>\n",
              "      <td>East Asian</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1887</th>\n",
              "      <td>train/1888.jpg</td>\n",
              "      <td>50-59</td>\n",
              "      <td>Female</td>\n",
              "      <td>Latino_Hispanic</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85721</th>\n",
              "      <td>train/85722.jpg</td>\n",
              "      <td>40-49</td>\n",
              "      <td>Male</td>\n",
              "      <td>East Asian</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12363</th>\n",
              "      <td>train/12364.jpg</td>\n",
              "      <td>20-29</td>\n",
              "      <td>Male</td>\n",
              "      <td>East Asian</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38531</th>\n",
              "      <td>train/38532.jpg</td>\n",
              "      <td>10-19</td>\n",
              "      <td>Male</td>\n",
              "      <td>Latino_Hispanic</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33590</th>\n",
              "      <td>train/33591.jpg</td>\n",
              "      <td>40-49</td>\n",
              "      <td>Female</td>\n",
              "      <td>Black</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>69395 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  file    age  gender             race  service_test\n",
              "82770  train/82771.jpg  10-19    Male            White         False\n",
              "80112  train/80113.jpg  40-49    Male  Latino_Hispanic         False\n",
              "23469  train/23470.jpg  40-49  Female  Latino_Hispanic          True\n",
              "37598  train/37599.jpg  40-49  Female       East Asian          True\n",
              "63855  train/63856.jpg  40-49    Male       East Asian          True\n",
              "...                ...    ...     ...              ...           ...\n",
              "1887    train/1888.jpg  50-59  Female  Latino_Hispanic         False\n",
              "85721  train/85722.jpg  40-49    Male       East Asian         False\n",
              "12363  train/12364.jpg  20-29    Male       East Asian          True\n",
              "38531  train/38532.jpg  10-19    Male  Latino_Hispanic         False\n",
              "33590  train/33591.jpg  40-49  Female            Black          True\n",
              "\n",
              "[69395 rows x 5 columns]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_labels_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aTI7lCD6DCV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "def weighted_categorical_crossentropy(weights):\n",
        "    \"\"\"\n",
        "    A weighted version of keras.objectives.categorical_crossentropy\n",
        "    \n",
        "    Variables:\n",
        "        weights: numpy array of shape (C,) where C is the number of classes\n",
        "    \"\"\"\n",
        "    \n",
        "    weights = K.variable(weights)\n",
        "        \n",
        "    def loss(y_true, y_pred):\n",
        "        # scale predictions so that the class probas of each sample sum to 1\n",
        "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
        "        # clip to prevent NaN's and Inf's\n",
        "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
        "        # calc\n",
        "        loss = tf.dtypes.cast(y_true, tf.float64) * tf.dtypes.cast(K.log(y_pred), tf.float64) * tf.dtypes.cast(weights, tf.float64)\n",
        "        loss = -K.sum(loss, -1)\n",
        "        return loss\n",
        "    \n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exYoW0hdQLVN"
      },
      "source": [
        "Preprocess Image with JPEG compression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NJ4pHWyh0AmL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import imgaug.augmenters as iaa\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def jpeg_compress(np_image):\n",
        "  # This function can only work with this datatype\n",
        "  img_list = [np_image.astype(\"uint8\")]\n",
        "  \n",
        "  # 60 - 75 means, a quality of 40 - 25\n",
        "  seq_free = iaa.Sequential(\n",
        "    [iaa.JpegCompression(compression=(60, 75))]\n",
        "  )\n",
        "   \n",
        "  return seq_free(images=img_list)[0].astype(\"float32\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5s7PZR887rZ"
      },
      "source": [
        "# AE model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAdX0DTSQPIf"
      },
      "source": [
        "Create Data Generators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSyG795k8-RA"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import random \n",
        "import numpy as np\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "  rescale=1./255,\n",
        "  preprocessing_function = jpeg_compress\n",
        ")\n",
        "\n",
        "validate_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "common_generator_settings = {\n",
        "  \"x_col\": \"file\",\n",
        "  \"class_mode\": 'input',\n",
        "  \"seed\": RANDOM_SEED,\n",
        "  \"target_size\": (224, 224),\n",
        "  \"validate_filenames\": True\n",
        "}\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "  dataframe=train_labels_df,\n",
        "  batch_size=8,\n",
        "  **common_generator_settings\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "  dataframe=test_labels_df,\n",
        "  **common_generator_settings\n",
        ")\n",
        "\n",
        "validate_generator = validate_datagen.flow_from_dataframe(\n",
        "  dataframe=validate_labels_df,\n",
        "  batch_size=VALIDATE_BATCH_SIZE,\n",
        "  **common_generator_settings\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ta_N2Vm09LHw"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4mBaL1g0Jk6"
      },
      "source": [
        "Load the previously trained classification model without the Dense layers, then add a decoder network to it so it can function as an AutoEncoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4KAQSvv9Apu"
      },
      "outputs": [],
      "source": [
        "model=keras.models.load_model('/content/drive/MyDrive/figures/model.hdf5', custom_objects={'loss': weighted_categorical_crossentropy})\n",
        "\n",
        "input=model.input\n",
        "\n",
        "for layer in model.layers[:-5]:\n",
        "  layer.trainable=False\n",
        "\n",
        "x=model.layers[-6].output\n",
        "\n",
        "code=x\n",
        "\n",
        "encoder=keras.Model(input, code)\n",
        "\n",
        "x=keras.layers.Reshape((1, 1, 512))(code)\n",
        "\n",
        "x=keras.layers.UpSampling2D((7,7))(x)\n",
        "\n",
        "for filter in [512]:\n",
        "  x=keras.layers.Conv2D(filter, kernel_size=3, padding='same', activation='relu')(x)\n",
        "  x=keras.layers.Conv2D(filter, kernel_size=3, padding='same', activation='relu')(x)\n",
        "  x=keras.layers.Conv2D(filter, kernel_size=3, padding='same', activation='relu')(x)\n",
        "  x=keras.layers.UpSampling2D((2,2))(x)\n",
        "\n",
        "for filter in [512, 256]:\n",
        "  x=keras.layers.Conv2D(filter, kernel_size=3, padding='same', activation='relu')(x)\n",
        "  x=keras.layers.Conv2D(filter, kernel_size=3, padding='same', activation='relu')(x)\n",
        "  x=keras.layers.Conv2D(filter, kernel_size=3, padding='same', activation='relu')(x)\n",
        "  x=keras.layers.UpSampling2D((2,2))(x)\n",
        "for filter in [128, 64]:\n",
        "  x=keras.layers.Conv2D(filter, kernel_size=3, padding='same', activation='relu')(x)\n",
        "  x=keras.layers.Conv2D(filter, kernel_size=3, padding='same', activation='relu')(x)\n",
        "  x=keras.layers.UpSampling2D((2,2))(x)\n",
        "output=keras.layers.Conv2D(3, kernel_size=3, padding='same', activation='sigmoid')(x)\n",
        "\n",
        "\n",
        "ae=keras.Model(input, output)\n",
        "\n",
        "decoder_input=keras.Input(shape=(512))\n",
        "x=decoder_input\n",
        "for layer in ae.layers[len(encoder.layers):]:\n",
        "  x=layer(x)\n",
        "decoder_output=x\n",
        "\n",
        "decoder=keras.Model(decoder_input, decoder_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-UL2J9k9TfF"
      },
      "outputs": [],
      "source": [
        "ae.summary()\n",
        "encoder.summary()\n",
        "decoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5OO7jz5BMp1"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "from datetime import datetime\n",
        "\n",
        "checkpointer=ModelCheckpoint(filepath='/content/drive/MyDrive/figures/ae_model.hdf5', save_best_only=True, monitor='loss', verbose=1)\n",
        "\n",
        "ae.compile(optimizer='adam', loss='mse')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "P3vQIceo_yEp",
        "outputId": "4f418a06-5ce4-4c6d-e5b9-a623693d474f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1734/1734 [==============================] - ETA: 0s - loss: 0.0361\n",
            "Epoch 00001: loss improved from inf to 0.03611, saving model to /content/drive/MyDrive/figures/ae_model.hdf5\n",
            "1734/1734 [==============================] - 562s 315ms/step - loss: 0.0361\n",
            "Epoch 2/10\n",
            "1734/1734 [==============================] - ETA: 0s - loss: 0.0288\n",
            "Epoch 00002: loss improved from 0.03611 to 0.02882, saving model to /content/drive/MyDrive/figures/ae_model.hdf5\n",
            "1734/1734 [==============================] - 540s 311ms/step - loss: 0.0288\n",
            "Epoch 3/10\n",
            "1734/1734 [==============================] - ETA: 0s - loss: 0.0270\n",
            "Epoch 00003: loss improved from 0.02882 to 0.02702, saving model to /content/drive/MyDrive/figures/ae_model.hdf5\n",
            "1734/1734 [==============================] - 540s 311ms/step - loss: 0.0270\n",
            "Epoch 4/10\n",
            " 436/1734 [======>.......................] - ETA: 6:42 - loss: 0.0264"
          ]
        }
      ],
      "source": [
        "ae.fit(\n",
        "  train_generator,\n",
        "  steps_per_epoch=TRAIN_SIZE//8,\n",
        "  epochs=10,\n",
        "  callbacks=(checkpointer)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRL41uXw0f46"
      },
      "source": [
        "Load 10 pictures from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erhlUgpEXZmW"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import tqdm\n",
        "import matplotlib\n",
        "x_train=np.empty((10, 224, 224, 3), dtype=np.uint8)\n",
        "imgs=glob.glob(\"train/*.jpg\")\n",
        "img_count=0\n",
        "for img in tqdm.tqdm(imgs):\n",
        "   x_train[img_count]=matplotlib.image.imread(img)\n",
        "\n",
        "   img_count+=1\n",
        "   \n",
        "   if(img_count==10):\n",
        "     break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iBjVjCU0k1i"
      },
      "source": [
        "Load previously saved AutoEncoder model if necessary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FRsTWbcAFMZ"
      },
      "outputs": [],
      "source": [
        "ae=keras.models.load_model(filepath='/content/drive/MyDrive/figures/ae_model.hdf5')\n",
        "encoder=keras.Model(ae.input, ae.layers[19].output)\n",
        "\n",
        "decoder_input=keras.Input(shape=(512))\n",
        "x=decoder_input\n",
        "for layer in ae.layers[len(encoder.layers):]:\n",
        "  x=layer(x)\n",
        "decoder_output=x\n",
        "\n",
        "decoder=keras.Model(decoder_input, decoder_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNWlxh8WcDkN"
      },
      "source": [
        "Linear interpolation between two pictures using the latent space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4jM9CvJXFt0"
      },
      "outputs": [],
      "source": [
        "from matplotlib import animation\n",
        "import tqdm\n",
        "def lin_pol(x1, x2, encoder, decoder, name='proba.mp4'):\n",
        "  '''Generates animation that shows the linear interpolation between samples\n",
        "\n",
        "  Params:\n",
        "    x1, x2:\n",
        "      Input samples, linear interpolation will be done from x1 to x2\n",
        "    encoder:\n",
        "      Encoder model of the AutoEncoder network\n",
        "    decoder:\n",
        "      Decoder model of the AutoEncoder network\n",
        "    name:\n",
        "      Name of the animation file that will be saved.\n",
        "  \n",
        "  Usage:\n",
        "    Example usage of the function:\n",
        "\n",
        "    >>>lin_pol(x_train[0:1], x_train[8:9], encoder, decoder, name='ae_lin_pol_0_9.mp4')\n",
        "    100%|██████████| 501/501 [09:51<00:00,  1.18s/it]\n",
        "\n",
        "  '''\n",
        "  fig=plt.figure(figsize=(8,8))\n",
        "  ax=fig.add_subplot(111)\n",
        "  code1=encoder(x1/255)\n",
        "  code2=encoder(x2/255)\n",
        "  code=np.zeros((1, 512))\n",
        "  ims=[]\n",
        "  for i in tqdm.tqdm(range(500+1)):\n",
        "    for j in range(512):\n",
        "      code[0][j]=code1[0][j]+(code2[0][j]-code1[0][j])/500*i\n",
        "    ttl = plt.text(0.5, 1.01, str(i/5)+\"% sample\", horizontalalignment='center', verticalalignment='bottom', transform=ax.transAxes)\n",
        "    im=plt.imshow(decoder(code)[0])\n",
        "    ims.append([im, ttl])\n",
        "  ani=animation.ArtistAnimation(fig, ims, blit=True, interval=50)\n",
        "  ani.save(\"/content/drive/MyDrive/figures/\"+name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqEiktyXXLbD"
      },
      "outputs": [],
      "source": [
        "plt.imshow(x_train[0])\n",
        "plt.show()\n",
        "plt.imshow(x_train[9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VbpOG8CX0oK"
      },
      "outputs": [],
      "source": [
        "lin_pol(x_train[0:1], x_train[8:9], encoder, decoder, name='ae_lin_pol_0_9.mp4')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "AutoEncoder.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
